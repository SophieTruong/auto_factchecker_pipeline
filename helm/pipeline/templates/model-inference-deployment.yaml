---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: model-inference
  namespace: {{ $.Release.Namespace }}
  labels:
    app.kubernetes.io/component: server
    app.kubernetes.io/name: model-inference
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: server
      app.kubernetes.io/name: model-inference
  template:
    metadata:
      labels:
        app.kubernetes.io/component: server
        app.kubernetes.io/name: model-inference
    spec:
      containers:
        - name: model-inference-pod
          image: "{{ .Values.model_inference_image_url }}:{{ .Values.model_inference_image_tag }}"          
          resources:
            requests:
              cpu: 125m
            limits: 
              cpu: 1000m
          env:
            - { name: MODEL_METADATA, value: {{ .Values.model_metadata }} }
            - { name: MODEL_URI,  value: {{ .Values.model_uri }} }
            - name: RABBITMQ_HOST
              value: "{{ .Values.rabbitmq_service_name }}:{{ .Values.rabbitmq_service_port }}"
            - name: RABBITMQ_USER
              value: "{{ .Values.rabbitmq_user }}"
            - name: RABBITMQ_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: databases
                  key: rabbitmq_password   
            - name: RABBITMQ_VHOST
              value: "{{ .Values.rabbitmq_vhost }}"
          volumeMounts:
            - mountPath: /app/mlruns
              name: {{ .Values.model_volume }}
      volumes:
        - name: {{ .Values.model_volume }}
          persistentVolumeClaim:
            claimName: {{ .Values.model_volume }}