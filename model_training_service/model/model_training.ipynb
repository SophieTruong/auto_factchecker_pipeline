{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45b729eb-22d6-478f-87f4-e9fb698652b7",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_training.py\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(\n",
    "                os.path.dirname(os.path.dirname(os.path.abspath(\"__file__\"))))\n",
    "               )\n",
    "\n",
    "sys.path.append(os.path.join(\n",
    "                os.path.dirname(os.path.dirname(os.path.abspath(\"__file__\"))),\n",
    "                'model_training_service')\n",
    "               )\n",
    "sys.path.append(os.path.join(\n",
    "                os.path.dirname(os.path.dirname(os.path.abspath(\"__file__\"))),\n",
    "                'model_training_service',\n",
    "                'data')\n",
    "               )\n",
    "\n",
    "print(sys.path)\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "from data.data_processing import get_text_label, get_data_splits, shape_data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from setfit import SetFitModel, Trainer, TrainingArguments, sample_dataset\n",
    "from sentence_transformers import InputExample, SentenceTransformer, losses\n",
    "\n",
    "from sklearn.metrics import f1_score, balanced_accuracy_score, accuracy_score, confusion_matrix, multilabel_confusion_matrix\n",
    "\n",
    "import torch\n",
    "\n",
    "# Model tracking\n",
    "import wandb\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "from mlflow.pyfunc import PythonModel\n",
    "\n",
    "\n",
    "# Model parameter tuning\n",
    "import optuna\n",
    "\n",
    "class SetFitCustomModel(PythonModel):\n",
    "    def load_context(self, context):\n",
    "        self.model = SetFitModel.from_pretrained(context.artifacts['snapshot'])\n",
    "\n",
    "    def predict(self, context, model_input):\n",
    "        predicts = self.model.predict(model_input)\n",
    "        return predicts\n",
    "\n",
    "def get_or_create_experiment(experiment_name):\n",
    "    \"\"\"\n",
    "    Retrieve the ID of an existing MLflow experiment or create a new one if it doesn't exist.\n",
    "\n",
    "    This function checks if an experiment with the given name exists within MLflow.\n",
    "    If it does, the function returns its ID. If not, it creates a new experiment\n",
    "    with the provided name and returns its ID.\n",
    "\n",
    "    Parameters:\n",
    "    - experiment_name (str): Name of the MLflow experiment.\n",
    "\n",
    "    Returns:\n",
    "    - str: ID of the existing or newly created MLflow experiment.\n",
    "    \"\"\"\n",
    "\n",
    "    if experiment := mlflow.get_experiment_by_name(experiment_name):\n",
    "        return experiment.experiment_id\n",
    "    else:\n",
    "        return mlflow.create_experiment(experiment_name)\n",
    "\n",
    "def set_model(multi_label=False):\n",
    "    # Load a SetFit model from Hub \n",
    "    pretrained_model_name = 'FacebookAI/xlm-roberta-base' #'TurkuNLP/bert-base-finnish-cased-v1'\n",
    "    if multi_label:\n",
    "        model = SetFitModel.from_pretrained(pretrained_model_name, multi_target_strategy=\"multi-output\")\n",
    "    else:\n",
    "        model = SetFitModel.from_pretrained(pretrained_model_name)\n",
    "    return model, pretrained_model_name\n",
    "\n",
    "def config_wandb(multi_label, pretrained_model_name):\n",
    "    config = {'learning_rate': 3.0191843531454982e-05, 'num_epochs': 4, 'batch_size': 16, 'seed': 34, 'num_iterations': 6}\n",
    "\n",
    "    wandb.init(\n",
    "        project=\"Claim-detection\",\n",
    "        notes=\"initial\",\n",
    "        tags=[\"Henna\", \"binary\", \"single label\" if multi_label else 'binary', 'first_test', 'DIME_data_HennaPipsaMinttu', 'ei-tark_henkkoht_muu==0', pretrained_model_name],\n",
    "        config=config,\n",
    "    )\n",
    "    return wandb, config \n",
    "    \n",
    "def f1_score_weighted(y_true, y_pred):\n",
    "    return f1_score(y_true.numpy(), np.array(y_pred), average='weighted')\n",
    "\n",
    "def train_model(model, train_ds, dev_ds, config):\n",
    "    args = TrainingArguments(\n",
    "        batch_size=16,\n",
    "        num_epochs=4,\n",
    "        eval_strategy=\"epoch\", #\"epoch\",\n",
    "        save_strategy=\"epoch\", #\"epoch\",\n",
    "        load_best_model_at_end=False,\n",
    "        num_iterations=6,\n",
    "        loss=losses.CosineSimilarityLoss,\n",
    "        report_to=\"mlflow\",\n",
    "    )\n",
    "    args.eval_strategy = args.evaluation_strategy\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        train_dataset=train_ds,\n",
    "        args=args,\n",
    "        eval_dataset=dev_ds,\n",
    "        metric= f1_score_weighted\n",
    "    )\n",
    "\n",
    "    # Train and evaluate\n",
    "    \n",
    "    trainer.train()\n",
    "    metric = trainer.evaluate()\n",
    "    print(metric)\n",
    "    return model, metric, trainer\n",
    "\n",
    "def get_predictions(model, test_df, multi_label):    \n",
    "    # model = new_model\n",
    "    # Run inference\n",
    "    preds = model.predict(test_df['text'], as_numpy=True)\n",
    "    probs = model.predict_proba(test_df['text'], as_numpy=True)\n",
    "    probsmax = np.max(probs, axis=1)\n",
    "\n",
    "    if not multi_label:\n",
    "        # preds_labels = [classes[i] for i in preds]\n",
    "        y_true = test_df['label']\n",
    "        y_pred = preds\n",
    "    else:\n",
    "        y_true = test_df.drop(columns=['text']).values\n",
    "        y_pred = preds\n",
    "    return preds, probs, y_true, y_pred #probsmax\n",
    "\n",
    "\n",
    "def print_confusion_matrix(confusion_matrix_data, axes, class_label, class_names, fontsize=14):\n",
    "\n",
    "    df_cm = pd.DataFrame(\n",
    "        confusion_matrix_data, index=class_names, columns=class_names,\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\", cbar=False, ax=axes)\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "    axes.set_ylabel('True label')\n",
    "    axes.set_xlabel('Predicted label')\n",
    "    axes.set_title(\"Confusion Matrix for the class - \" + class_label)\n",
    "\n",
    "def get_confusion_matrix(multi_label, wandb, y_true, y_pred, classes):\n",
    "    if not multi_label:\n",
    "        wandb.log({\"confusion matrix\" : wandb.plot.confusion_matrix(probs=None,\n",
    "                                y_true=y_true, preds=y_pred,\n",
    "                                class_names=classes)})\n",
    "\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        df_cm = pd.DataFrame(cm, index = classes, columns = classes)\n",
    "        plt.figure(figsize = (10,7))\n",
    "        sns.heatmap(df_cm, annot=True)\n",
    "    else:\n",
    "        cm = multilabel_confusion_matrix(y_true, y_pred)\n",
    "\n",
    "        fig, ax = plt.subplots(5, 3, figsize=(12, 12))\n",
    "\n",
    "        for axes, cfs_matrix, label in zip(ax.flatten(), cm, classes):\n",
    "            print_confusion_matrix(cfs_matrix, axes, label, [\"N\", \"Y\"])\n",
    "\n",
    "        fig.tight_layout()\n",
    "        plt.show()   \n",
    "        wandb.log({\"confusion matrix 2\": wandb.Image(plt)})\n",
    "        \n",
    "def get_classification_report(y_true, y_pred):\n",
    "    classes0 = ['True', 'False']\n",
    "    from sklearn.metrics import classification_report\n",
    "    print(classification_report(y_true, y_pred, target_names=classes0, zero_division=0))\n",
    "\n",
    "def get_evaluation_metrics(y_true, y_pred, probs, preds, wandb):\n",
    "    micro_f1_score = f1_score(y_true, y_pred, average='micro')\n",
    "    wandb.log({\"f1-score micro\": micro_f1_score})\n",
    "    print('f1-score micro', f1_score(y_true, y_pred, average='micro'))\n",
    "\n",
    "    macro_f1_score = f1_score(y_true, y_pred, average='macro')\n",
    "    wandb.log({\"f1-score macro\": macro_f1_score})\n",
    "    print('f1-score macro', macro_f1_score)\n",
    "\n",
    "    weighted_f1_score = f1_score(y_true, y_pred, average='weighted')\n",
    "    wandb.log({\"f1-score weighted\": weighted_f1_score})\n",
    "    print('f1-score weighted', weighted_f1_score)\n",
    "\n",
    "    balanced_accuracy = balanced_accuracy_score(y_true, y_pred)\n",
    "    wandb.log({\"balanced accuracy\": balanced_accuracy})\n",
    "    print('balanced accuracy', balanced_accuracy)\n",
    "    \n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    wandb.log({\"accuracy\": accuracy})\n",
    "    print('accuracy ', accuracy)\n",
    "    \n",
    "    return balanced_accuracy, accuracy, macro_f1_score, micro_f1_score, weighted_f1_score\n",
    "    \n",
    "def write_metrics_to_file(state_r, balanced_accuracy, accuracy, macro_f1_score, micro_f1_score, weighted_f1_score,pretrained_model_name):\n",
    "    lines= [' ,', ' ,',pretrained_model_name, ' ,',str(state_r),' ,', 'DIME_data_HennaMinttuPipsa_all_labels',' ,', 'balanced_accuracy:',' ,', str(balanced_accuracy),' ,', 'accuracy:',' ,', str(accuracy),' ,',\n",
    "       'macro-f1:',' ,', str(macro_f1_score),' ,', 'micro_f1_score:',' ,', str(micro_f1_score),' ,', 'weighted f1:', ' ,',str(weighted_f1_score),' ,', '\\n']\n",
    "\n",
    "    with open('setfit_claim_detection_DIME_data_HennaMinttuPipsa_all_labels_henkkoht-eitarkist-muu==0.txt', 'a') as f:\n",
    "        f.writelines(lines)\n",
    "        \n",
    "def main():\n",
    "    # setting device on GPU if available, else CPU\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print('Using device:', device)\n",
    "    print()\n",
    "    \n",
    "    #Additional Info when using cuda\n",
    "    if device.type == 'cuda':\n",
    "        print(torch.cuda.get_device_name(0))\n",
    "\n",
    "    data_path = os.path.join(\n",
    "                os.path.dirname(os.path.dirname(os.path.abspath(\"__file__\"))),\n",
    "                'app', \n",
    "                os.environ.get(\"DATA_PATH\")\n",
    "    )\n",
    "    multi_label = False\n",
    "\n",
    "    ## Inspect the data reading, spliting code\n",
    "    random_states=[1,2,3,4,5]#,6,7,8,9,10]\n",
    "\n",
    "    texts, labels = get_text_label(data_path)\n",
    "\n",
    "    # Set up MLFlow tracking\n",
    "    experiment_name = f\"/Users/{os.getenv('MLFLOW_TRACKING_USERNAME')}/claim-detection-setfit-Facebook-XML\"\n",
    "    experiment_id = get_or_create_experiment(experiment_name)\n",
    "\n",
    "    mlflow.set_experiment(\n",
    "        experiment_id = experiment_id\n",
    "    )\n",
    "    run_name = \"setfit-Facebook-XML-Henna-training\"\n",
    "    with mlflow.start_run(experiment_id=experiment_id, run_name=run_name, nested=True):\n",
    "        # Log tags\n",
    "        mlflow.set_tags(\n",
    "            tags={\n",
    "                \"project\": \"DIME Claim Detection model\",\n",
    "                \"optimizer_engine\": \"manual\",\n",
    "                \"model_family\": \"setfit-Facebook-XML\",\n",
    "                \"feature_set_version\": 1,\n",
    "            }\n",
    "        )\n",
    "        for state_x in random_states:\n",
    "            with mlflow.start_run(nested=True):\n",
    "                train_df, test_df1, dev_df, test_scores= get_data_splits(state_x, texts, labels)\n",
    "            \n",
    "                train_ds, test_ds, dev_ds, test_df= shape_data(train_df, test_df1, dev_df, multi_label)\n",
    "            \n",
    "                model, pretrained_model_name = set_model()\n",
    "            \n",
    "                wandb, config= config_wandb(multi_label, pretrained_model_name) \n",
    "            \n",
    "                model, metric, trainer= train_model(model, train_ds, dev_ds, config) \n",
    "                \n",
    "                preds, probs, y_true, y_pred= get_predictions(model, test_df, multi_label)\n",
    "            \n",
    "                get_classification_report(y_true, y_pred)\n",
    "            \n",
    "                balanced_accuracy, accuracy, macro_f1_score, micro_f1_score, weighted_f1_score= get_evaluation_metrics(y_true, y_pred,probs, preds, wandb)\n",
    "            \n",
    "                write_metrics_to_file(state_x, balanced_accuracy, accuracy, macro_f1_score, micro_f1_score, weighted_f1_score,pretrained_model_name)\n",
    "                            \n",
    "                # First, save the finetuned model locally\n",
    "                model.save_pretrained('snapshot')\n",
    "\n",
    "                # Log the hyperparameters\n",
    "                config[\"train_test_split_random_state\"] = state_x\n",
    "                mlflow.log_params({\n",
    "                    \"train_test_split_random_state\":state_x,\n",
    "                    \"device\": torch.cuda.get_device_name(0)\n",
    "                })\n",
    "\n",
    "                # Log the loss metric\n",
    "                mlflow.log_metric(\"f1-score micro\", micro_f1_score)\n",
    "                mlflow.log_metric(\"f1-score macro\", macro_f1_score)\n",
    "                mlflow.log_metric(\"f1-score weighted\", weighted_f1_score)\n",
    "                mlflow.log_metric(\"balanced accuracy\", balanced_accuracy)\n",
    "                mlflow.log_metric(\"accuracy\", accuracy)\n",
    "                \n",
    "                # Log the model\n",
    "                artifact_path = \"setfit_model\"\n",
    "                model_info = mlflow.pyfunc.log_model(\n",
    "                    artifact_path=artifact_path,\n",
    "                    artifacts={'snapshot': 'snapshot'},\n",
    "                    python_model=SetFitCustomModel(),\n",
    "                    conda_env='conda-env.yml',\n",
    "                    registered_model_name=\"claim-detection-setfit-TurkuNLP\",\n",
    "                )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46a269b6-aae1-44f6-9d10-952414b0e8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/scratch/work/truongl3/.conda_envs/claim-model-training-env/lib/python312.zip', '/scratch/work/truongl3/.conda_envs/claim-model-training-env/lib/python3.12', '/scratch/work/truongl3/.conda_envs/claim-model-training-env/lib/python3.12/lib-dynload', '', '/home/truongl3/.local/lib/python3.12/site-packages', '/scratch/work/truongl3/.conda_envs/claim-model-training-env/lib/python3.12/site-packages', '/scratch/work/truongl3/DIME/Henna_claim_detection_model', '/scratch/work/truongl3/DIME/Henna_claim_detection_model/Henna_claim_detection_model']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/work/truongl3/.conda_envs/claim-model-training-env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/scratch/work/truongl3/.conda_envs/claim-model-training-env/lib/python3.12/site-packages/mlflow/gateway/config.py:64: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
      "  @validator(\"togetherai_api_key\", pre=True)\n",
      "/scratch/work/truongl3/.conda_envs/claim-model-training-env/lib/python3.12/site-packages/mlflow/gateway/config.py:78: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
      "  @validator(\"cohere_api_key\", pre=True)\n",
      "/scratch/work/truongl3/.conda_envs/claim-model-training-env/lib/python3.12/site-packages/mlflow/gateway/config.py:86: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
      "  @validator(\"ai21labs_api_key\", pre=True)\n",
      "/scratch/work/truongl3/.conda_envs/claim-model-training-env/lib/python3.12/site-packages/mlflow/gateway/config.py:95: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
      "  @validator(\"mosaicml_api_key\", pre=True)\n",
      "/scratch/work/truongl3/.conda_envs/claim-model-training-env/lib/python3.12/site-packages/mlflow/gateway/config.py:125: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
      "  @validator(\"openai_api_key\", pre=True)\n",
      "/scratch/work/truongl3/.conda_envs/claim-model-training-env/lib/python3.12/site-packages/mlflow/gateway/config.py:182: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
      "  @validator(\"anthropic_api_key\", pre=True)\n",
      "/scratch/work/truongl3/.conda_envs/claim-model-training-env/lib/python3.12/site-packages/mlflow/gateway/config.py:190: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
      "  @validator(\"palm_api_key\", pre=True)\n",
      "/scratch/work/truongl3/.conda_envs/claim-model-training-env/lib/python3.12/site-packages/mlflow/gateway/config.py:230: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
      "  @validator(\"mistral_api_key\", pre=True)\n",
      "/scratch/work/truongl3/.conda_envs/claim-model-training-env/lib/python3.12/site-packages/mlflow/gateway/config.py:284: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
      "  @validator(\"provider\", pre=True)\n",
      "/scratch/work/truongl3/.conda_envs/claim-model-training-env/lib/python3.12/site-packages/mlflow/gateway/config.py:311: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
      "  @validator(\"config\", pre=True)\n",
      "/scratch/work/truongl3/.conda_envs/claim-model-training-env/lib/python3.12/site-packages/mlflow/gateway/config.py:351: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
      "  @validator(\"name\")\n",
      "/scratch/work/truongl3/.conda_envs/claim-model-training-env/lib/python3.12/site-packages/mlflow/gateway/config.py:361: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
      "  @validator(\"model\", pre=True)\n",
      "/scratch/work/truongl3/.conda_envs/claim-model-training-env/lib/python3.12/site-packages/mlflow/gateway/config.py:372: PydanticDeprecatedSince20: Pydantic V1 style `@root_validator` validators are deprecated. You should migrate to Pydantic V2 style `@model_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
      "  @root_validator(skip_on_failure=True)\n",
      "/scratch/work/truongl3/.conda_envs/claim-model-training-env/lib/python3.12/site-packages/mlflow/gateway/config.py:394: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
      "  @validator(\"route_type\", pre=True)\n",
      "/scratch/work/truongl3/.conda_envs/claim-model-training-env/lib/python3.12/site-packages/mlflow/gateway/config.py:400: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
      "  @validator(\"limit\", pre=True)\n",
      "/home/truongl3/.local/lib/python3.12/site-packages/pydantic/_internal/_config.py:291: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
      "  warnings.warn(DEPRECATION_MESSAGE, DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(\n",
    "                os.path.dirname(os.path.dirname(os.path.abspath(\"__file__\"))))\n",
    "               )\n",
    "\n",
    "sys.path.append(os.path.join(\n",
    "                os.path.dirname(os.path.dirname(os.path.abspath(\"__file__\"))),\n",
    "                'Henna_claim_detection_model')\n",
    "               )\n",
    "print(sys.path)\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "from data.data_processing import get_text_label, get_data_splits, shape_data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from setfit import SetFitModel, Trainer, TrainingArguments, sample_dataset\n",
    "from sentence_transformers import InputExample, SentenceTransformer, losses\n",
    "\n",
    "from sklearn.metrics import f1_score, balanced_accuracy_score, accuracy_score, confusion_matrix, multilabel_confusion_matrix\n",
    "\n",
    "import torch\n",
    "\n",
    "# Model tracking\n",
    "import wandb\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "from mlflow.pyfunc import PythonModel\n",
    "\n",
    "\n",
    "# Model parameter tuning\n",
    "import optuna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7429943-69c3-45b2-80db-7d8eaa343f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nSuomen sää jatkuu loppiaisena kylmänä ja poutaisena',\n",
       " ' Pakkasta on koko maassa ja lukemat vaihtelevat etelän 1–9 pakkasasteesta pohjoisen 10–20 pakkasasteeseen',\n",
       " ' Vähäisiä lumisateita tulee aamulla paikoin idässä ja pohjoisessa, mutta muuten sää on enimmäkseen poutainen',\n",
       " '\\n\\nLoppiaista seuraa muutos',\n",
       " ' Tiistain vastaisena yönä maahan leviää lumisadealue, joka liikkuu päivän kuluessa maan etelä- ja keskiosan yllä hitaasti pohjoiseen',\n",
       " ' Lounaisilla ja läntisillä merialueilla voi esiintyä myrskypuuskia',\n",
       " '\\n\\nLunta tulee etelässä ja maan keskiosassa tiistain aikana 5–10 senttimetriä',\n",
       " ' Sadealueen yhteydessä pakkasta on 1–5 astetta, pohjoisemmassa 10–20 astetta',\n",
       " '\\n\\nIlmatieteen laitoksen varoituskartalla varoitetaan heikosta ajokelistä suuressa osassa maata',\n",
       " ' Ajokeli on kehno koko maassa Kuusamosta etelään lumisateiden, jäätävän tihkusateen ja sään lauhtumisen vuoksi',\n",
       " '\\n\\nSadealueen jälkeen sää lauhtuu ja lämpötila nousee 1–3 plusasteeseen',\n",
       " '\\n\\nKeskiviikkona Suomen yllä on kaksi sadealuetta',\n",
       " ' Idässä lumisateet liikkuvat kohti pohjoista ja etelässä illaksi voi levitä sateita',\n",
       " ' Etelä- ja lounaisrannikolla lämpötila on nollan tuntumassa, joten sateet voivat tulla myös vetenä',\n",
       " '\\n\\nTorstaina sää kylmenee jälleen',\n",
       " ' Sadealueet väistyvät ja sää muuttuu poutaisemmaksi',\n",
       " ' Pakkasta on etelässä viitisen astetta ja Lapissa 15 astetta',\n",
       " '\\n\\n']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input_str = \"\"\"\n",
    "Suomen sää jatkuu loppiaisena kylmänä ja poutaisena. Pakkasta on koko maassa ja lukemat vaihtelevat etelän 1–9 pakkasasteesta pohjoisen 10–20 pakkasasteeseen. Vähäisiä lumisateita tulee aamulla paikoin idässä ja pohjoisessa, mutta muuten sää on enimmäkseen poutainen.\n",
    "\n",
    "Loppiaista seuraa muutos. Tiistain vastaisena yönä maahan leviää lumisadealue, joka liikkuu päivän kuluessa maan etelä- ja keskiosan yllä hitaasti pohjoiseen. Lounaisilla ja läntisillä merialueilla voi esiintyä myrskypuuskia.\n",
    "\n",
    "Lunta tulee etelässä ja maan keskiosassa tiistain aikana 5–10 senttimetriä. Sadealueen yhteydessä pakkasta on 1–5 astetta, pohjoisemmassa 10–20 astetta.\n",
    "\n",
    "Ilmatieteen laitoksen varoituskartalla varoitetaan heikosta ajokelistä suuressa osassa maata. Ajokeli on kehno koko maassa Kuusamosta etelään lumisateiden, jäätävän tihkusateen ja sään lauhtumisen vuoksi.\n",
    "\n",
    "Sadealueen jälkeen sää lauhtuu ja lämpötila nousee 1–3 plusasteeseen.\n",
    "\n",
    "Keskiviikkona Suomen yllä on kaksi sadealuetta. Idässä lumisateet liikkuvat kohti pohjoista ja etelässä illaksi voi levitä sateita. Etelä- ja lounaisrannikolla lämpötila on nollan tuntumassa, joten sateet voivat tulla myös vetenä.\n",
    "\n",
    "Torstaina sää kylmenee jälleen. Sadealueet väistyvät ja sää muuttuu poutaisemmaksi. Pakkasta on etelässä viitisen astetta ja Lapissa 15 astetta.\n",
    "\n",
    "\"\"\".split(\".\")\n",
    "\n",
    "display(test_input_str)\n",
    "\n",
    "test_input = test_input_str\n",
    "\n",
    "loaded_model = mlflow.pyfunc.load_model('file:///scratch/work/truongl3/DIME/Henna_claim_detection_model/mlruns/545956540925470991/d9e49b962be2454199f249f7ba65878a/artifacts/setfit_model')\n",
    "# print(loaded_model.predict([\"A\", \"B\", \"C\"]))  # -> [\"A\", \"B\", \"C\"]\n",
    "loaded_model.predict(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "beeeb8a1-b5b9-4bc5-9a12-41399677c997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml = SetFitModel.from_pretrained('/scratch/work/truongl3/DIME/Henna_claim_detection_model/snapshot')\n",
    "ml(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ece440e5-87cc-4f63-bd15-982ffefb000d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/scratch/work/truongl3/.conda_envs/claim-model-training-env/lib/python312.zip', '/scratch/work/truongl3/.conda_envs/claim-model-training-env/lib/python3.12', '/scratch/work/truongl3/.conda_envs/claim-model-training-env/lib/python3.12/lib-dynload', '', '/home/truongl3/.local/lib/python3.12/site-packages', '/scratch/work/truongl3/.conda_envs/claim-model-training-env/lib/python3.12/site-packages', '/scratch/work/truongl3/DIME/Henna_claim_detection_model', '/scratch/work/truongl3/DIME/Henna_claim_detection_model/Henna_claim_detection_model', '/scratch/work/truongl3/.conda_envs/claim-model-training-env/lib/python3.12/site-packages/setuptools/_vendor', '/tmp/tmpg1m52e37', '/scratch/work/truongl3/DIME/Henna_claim_detection_model', '/scratch/work/truongl3/DIME/Henna_claim_detection_model/Henna_claim_detection_model', '/scratch/work/truongl3/DIME/Henna_claim_detection_model', '/scratch/work/truongl3/DIME/Henna_claim_detection_model/data', '/scratch/work/truongl3/DIME/Henna_claim_detection_model', '/scratch/work/truongl3/DIME/Henna_claim_detection_model/data']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(\n",
    "                os.path.dirname(os.path.dirname(os.path.abspath(\"__file__\"))))\n",
    "               )\n",
    "\n",
    "sys.path.append(os.path.join(\n",
    "                os.path.dirname(os.path.dirname(os.path.abspath(\"__file__\"))),\n",
    "                'data')\n",
    "               )\n",
    "print(sys.path)\n",
    "from data.data_processing import get_text_label, get_data_splits, shape_data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "claim-model-training-env",
   "language": "python",
   "name": "internal_name"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
