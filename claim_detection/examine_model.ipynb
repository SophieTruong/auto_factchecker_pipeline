{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fabfd86-81cc-4eca-9f78-449db445479a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import mlflow\n",
    "from datasets import Dataset, load_from_disk\n",
    "import torch\n",
    "from transformers import (\n",
    "    XLMRobertaTokenizer,\n",
    "    XLMRobertaForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    AutoConfig,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d122c035-e62d-47a1-b6c6-ebc7a579a79b",
   "metadata": {},
   "source": [
    "## 1. Load test data and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac3ced0-5f1c-4bd8-8d69-efdce753012c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"FacebookAI/xlm-roberta-base\"\n",
    "# Preprocessing\n",
    "tokenizer = XLMRobertaTokenizer.from_pretrained(model_id)\n",
    "# This function tokenizes the input text using the RoBERTa tokenizer. \n",
    "# It applies padding and truncation to ensure that all sequences have the same length (256 tokens).\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True, max_length=256)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2779c5-065c-4a40-be02-7fecfd4aa0c1",
   "metadata": {},
   "source": [
    "## 2. Run model inference\n",
    "\n",
    "### a. Load metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeadf90e-bcdf-42c7-b07a-475c303bbc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "metric = evaluate.combine([\"accuracy\",\"f1\",\"recall\",\"precision\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c83a735-597f-4411-af1a-af028e5e459b",
   "metadata": {},
   "source": [
    "### b. Load model using Transformer lib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a962c4c1-5460-4ddb-8fcc-daa8f3985e88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XLMRobertaForSequenceClassification(\n",
       "  (roberta): XLMRobertaModel(\n",
       "    (embeddings): XLMRobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): XLMRobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): XLMRobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XLMRobertaForSequenceClassification.from_pretrained(\"xml-roberta-model\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4eba5ebb-6811-4c67-a109-6f713b20f0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 1.11G/1.11G [00:38<00:00, 28.9MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/SophieTr/xlm-roberta-base-claim-detection-clef21-24/commit/ac52276a9a4cb1d8dce269518e1da75354b35385', commit_message='Upload XLMRobertaForSequenceClassification', commit_description='', oid='ac52276a9a4cb1d8dce269518e1da75354b35385', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.push_to_hub(\"xlm-roberta-base-claim-detection-clef21-24\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3ce946-7e56-45f1-bde6-5eb214d6bb52",
   "metadata": {},
   "source": [
    "#### i. Test metric on 1 random data sample from training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa768b5-1f2b-4586-abe7-6fe9805b7024",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"Ekonomist Mahfi Eğilmes claimed that there are 100000 victims of the pandemic. 20% of them comes from Asia.\", return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "predicted_class_id = logits.argmax().item()\n",
    "display(f\"Predicted label: {model.config.id2label[predicted_class_id]}\")\n",
    "metric.compute([predicted_class_id],[1]) # predicts, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63056b16-d4d7-4036-be58-9c007bc061c0",
   "metadata": {},
   "source": [
    "#### ii. Test metric on Test data\n",
    "\n",
    "**NOTE**: TEST ON GPU will be much faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950364a0-7cee-426f-938b-dab62f5228c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test batch prediction using Trainer class on Test dataset\n",
    "def inference_test_set(\n",
    "    output_dir=\"./xml-roberta-test-log\",\n",
    "    test_path=\"./data/tokenized_dataset/test\"\n",
    "):\n",
    "    test_token = load_from_disk(test_path)\n",
    "    display(test_token)\n",
    "    \n",
    "    # TrainingArguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"{output_dir}\",\n",
    "        per_device_eval_batch_size=32,\n",
    "    )\n",
    "    \n",
    "    # Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "    )\n",
    "    \n",
    "    predicts = trainer.predict(test_token)\n",
    "    predictions = np.argmax(predicts.predictions, axis=-1)\n",
    "    labels = predicts.label_ids\n",
    "    \n",
    "    display(f\"Metrics on test dataset: {metric.compute(predictions=predictions, references=labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b172bdd6-194d-4841-be33-552713c09e54",
   "metadata": {},
   "source": [
    "#### iii. Test model inference on news articles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1450bd-5bab-4ee8-8e14-2da9cae1b5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"\"\"Iltalehden tietojen mukaan Pitäjänmäen McDonald’s-ravintolassa tapahtuneen henkirikoksen tutkintanimike on koventunut taposta murhaksi.\n",
    "\n",
    "Rikosnimike viittaa yleensä joko erityisen raakaan tai julmaan tekotapaan tai teon suunnitelmallisuuteen. Tapauksen tutkinnanjohtaja ei kommentoinut asiaa Iltalehdelle.\n",
    "\n",
    "21-vuotias pienen vauvan äiti sai surmansa 6. huhtikuuta. Poliisi epäilee teosta naisen entistä puolisoa, vauvan 30-vuotiasta isää.\n",
    "\n",
    "Miehen epäillään puukottaneen naista useita kertoja. Poliisi sai tiedon hätäkeskukselta noin kello 22.15 lauantai-iltana. Nainen kuoli saamiinsa vammoihin tapahtumapaikalla.\n",
    "\n",
    "Ennen tapahtumaa mies oli julkaissut sosiaalisessa mediassa videoita ja kirjoituksia naiseen liittyen. Videoilla hän puhui naisesta alatyyliseen ja uhkaavaan sävyyn.\n",
    "\n",
    "– Älä erota sitä lasta musta. (...) Mä pyydän nytten nätisti, toista kertaa en, mies sanoi yhdellä videoista.\n",
    "\n",
    "\"\"\".split(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b33560a-aa68-4771-984c-03a22d31f0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(test, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "display(logits)\n",
    "for i,t in enumerate(test):\n",
    "    predicted_class_id = logits[i].argmax().item()\n",
    "    print(t)\n",
    "    print(logits[i], predicted_class_id, model.config.id2label[predicted_class_id])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293c05e4-9b9e-4f80-992f-1a7f1f3a0e0f",
   "metadata": {},
   "source": [
    "### c. Load model using MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faf797a-536b-44d5-aeb2-169348a18b22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load model as a PyFuncModel.\n",
    "logged_model = \"dbfs:/databricks/mlflow-tracking/1266941859769377/a7378c8d769e4829b5ee714d9abd095a/artifacts/model\"\n",
    "\n",
    "# Uncomment this to download MLflow model\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7b58a9-e98c-4002-9446-53c2e99433a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = loaded_model.predict(test)\n",
    "predicts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3675b8f-1a5f-41fb-bb58-39332fc66b09",
   "metadata": {},
   "source": [
    "### 3. Model inference API\n",
    "\n",
    "- Preprocess input text into array of sentences\n",
    "- Tokenize sentences in batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2a94b71-95eb-4d5b-91ab-958a9895ffa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.fi.examples import sentences \n",
    "import torch\n",
    "from transformers import (\n",
    "    XLMRobertaTokenizer,\n",
    "    XLMRobertaForSequenceClassification,\n",
    ")\n",
    "\n",
    "model_id = \"FacebookAI/xlm-roberta-base\"\n",
    "\n",
    "# Preprocessing\n",
    "tokenizer = XLMRobertaTokenizer.from_pretrained(model_id)\n",
    "\n",
    "# Get model \n",
    "model = XLMRobertaForSequenceClassification.from_pretrained(\"xml-roberta-model\")\n",
    "\n",
    "nlp = spacy.load(\"fi_core_news_lg\")\n",
    "sentencizer = nlp.add_pipe(\"sentencizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a29681d2-7333-4951-8229-2a8636d856ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_array(doc: str):\n",
    "    return [str(s) for s in nlp(doc).sents]\n",
    "    \n",
    "def predicts(doc: str):\n",
    "    sentence_array = get_sentence_array(doc)\n",
    "    inputs = tokenizer(\n",
    "        sentence_array, \n",
    "        return_tensors=\"pt\", \n",
    "        padding=True, \n",
    "        truncation=True\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    predictions = [logits[i].argmax().item() for i,t in enumerate(logits)]\n",
    "    return sentence_array, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b105505-41ba-48a4-9ca4-ef62493ae621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Iltalehden tietojen mukaan Pitäjänmäen McDonald’s-ravintolassa tapahtuneen henkirikoksen tutkintanimike on koventunut taposta murhaksi.\\n\\n',\n",
       "  'Rikosnimike viittaa yleensä joko erityisen raakaan tai julmaan tekotapaan tai teon suunnitelmallisuuteen.',\n",
       "  'Tapauksen tutkinnanjohtaja ei kommentoinut asiaa Iltalehdelle.\\n\\n',\n",
       "  '21-vuotias pienen vauvan äiti sai surmansa 6. huhtikuuta.',\n",
       "  'Poliisi epäilee teosta naisen entistä puolisoa, vauvan 30-vuotiasta isää.\\n\\n',\n",
       "  'Miehen epäillään puukottaneen naista useita kertoja.',\n",
       "  'Poliisi sai tiedon hätäkeskukselta noin kello 22.15 lauantai-iltana.',\n",
       "  'Nainen kuoli saamiinsa vammoihin tapahtumapaikalla.\\n\\n',\n",
       "  'Ennen tapahtumaa mies oli julkaissut sosiaalisessa mediassa videoita ja kirjoituksia naiseen liittyen.',\n",
       "  'Videoilla hän puhui naisesta alatyyliseen ja uhkaavaan sävyyn.\\n\\n',\n",
       "  '– Älä erota sitä lasta musta.',\n",
       "  '(...) Mä pyydän nytten nätisti, toista kertaa en, mies sanoi yhdellä videoista.\\n\\n'],\n",
       " [1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = \"\"\"Iltalehden tietojen mukaan Pitäjänmäen McDonald’s-ravintolassa tapahtuneen henkirikoksen tutkintanimike on koventunut taposta murhaksi.\n",
    "\n",
    "Rikosnimike viittaa yleensä joko erityisen raakaan tai julmaan tekotapaan tai teon suunnitelmallisuuteen. Tapauksen tutkinnanjohtaja ei kommentoinut asiaa Iltalehdelle.\n",
    "\n",
    "21-vuotias pienen vauvan äiti sai surmansa 6. huhtikuuta. Poliisi epäilee teosta naisen entistä puolisoa, vauvan 30-vuotiasta isää.\n",
    "\n",
    "Miehen epäillään puukottaneen naista useita kertoja. Poliisi sai tiedon hätäkeskukselta noin kello 22.15 lauantai-iltana. Nainen kuoli saamiinsa vammoihin tapahtumapaikalla.\n",
    "\n",
    "Ennen tapahtumaa mies oli julkaissut sosiaalisessa mediassa videoita ja kirjoituksia naiseen liittyen. Videoilla hän puhui naisesta alatyyliseen ja uhkaavaan sävyyn.\n",
    "\n",
    "– Älä erota sitä lasta musta. (...) Mä pyydän nytten nätisti, toista kertaa en, mies sanoi yhdellä videoista.\n",
    "\n",
    "\"\"\"\n",
    "predicts(docs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "claim detection env",
   "language": "python",
   "name": "internal_name"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
